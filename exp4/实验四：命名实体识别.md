## 实验四



#### 实验简介：

​		命名实体识别（Named Entity Recognition, NER) 是NLP领域最经典的任务之一，实体识别提取一些专有的实体，如人名，地名，机构名，公司名，药品名等，实体识别广泛应用于搜索，对话，问答，知识库构建等场景中。基于transformer的BERT预训练模型相对于循环神经网络（Recurrent Neural Network，RNN）, 长短期记忆网络（Long Short-Term Memory, LSTM）以及传统的隐马尔科夫模型（Hidden Markov Model, HMM）、条件随机场（Conditional Random Field, CRF）能够更好地捕捉上下�## 实验四



#### 实验简介：

​		命名实体识别（Named Entity Recognition, NER) 是NLP领域最经典的任务之一，实体识别提取一些专有的实体，如人名，地名，机构名，公司名，药品名等，实体识别广泛应用于搜索，对话，问答，知识库构建等场景中。基于transformer的BERT预训练模型相对于循环神经网络（Recurrent Neural Network，RNN）, 长短期记忆网络（Long Short-Term Memory, LSTM）以及传统的隐马尔科夫模型（Hidden Markov Model, HMM）、条件随机场（Conditional Random Field, CRF）能够更好地捕捉上下文语义，从而提升识别性能。



#### 实验目的：

1.掌握命名实体识别（NER）相关基础知识点。

2.使用开源工具以及tensorflow等框架实现命名实体识别模型，加深对相关理论的理解。



#### 实验内容：

1.利用 Chinese.txt 和 English.txt 的中英文句子，在实验二的基础上，继续利用以下给定的中英文工具进行命名实体识别。并对不同工具产生的结果进行简要对比分析，将实验过程与结果写成实验报告，实验课结束后提交。

2.使用BERT + Bi-LSTM + CRF 实践命名实体识别，详细代码在BERT-LSTM-CRF压缩包，要求：运行代码，理解过程。

Dataset
实验数据来自CLUENER2020。这是一个中文细粒度命名实体识别数据集，是基于清华大学开源的文本分类数据集THUCNEWS，
选出部分数据进行细粒度标注得到的。该数据集的训练集、验证集和测试集的大小分别为10748，1343，1345，
平均句子长度37.4字，最长50字。由于测试集不直接提供，考虑到leaderboard上提交次数有限，
本项目使用CLUENER2020的验证集作为模型表现评判的测试集。
CLUENER2020共有10个不同的类别，包括：组织(organization)、人名(name)、地址(address)、
公司(company)、政府(government)、书籍(book)、游戏(game)、电影(movie)、职位(position)和景点(scene)。

原始数据分别位于具体模型的/data/clue/路径下，train.json和test.json文件中，文件中的每一行是一条单独的数据 ,
一条数据包括一个原始句子以及其上的标签，具体形式如下：

{
	"text": "浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，",
	"label": {
		"name": {
			"叶老桂": [
				[9, 11],
				[32, 34]
			]
		},
		"company": {
			"浙商银行": [
				[0, 3]
			]
		}
	}
}

This repo was tested on Python 3.6+ and PyTorch 1.5.1. The main requirements are:
tqdm
scikit-learn
pytorch >= 1.5.1
🤗transformers == 2.2.2

To get the environment settled, run:
pip install -r requirements.txt
Pretrained Model Required


Results
模型在数据集上的结果（f1 score）如下表所示：

实体名		Roberta+BiLSTM+CRF
address		    63.15
book		    81.45
company		    80.62
game		    85.57
government		81.31
movie		    85.61
name		    88.22
organization	80.53
position		78.82
scene		    72.86
overall		    79.64

Parameter Setting
1.model parameters
在./experiments/clue/config.json中设置了Bert模型的基本参数，
而在./pretrained_bert_models下的预训练文件夹中，config.json除了设置Bert的基本参数外，
还设置了LSTM参数，可根据需要进行更改。

2.other parameters
环境路径以及其他超参数在./config.py中进行设置。

3.run
python run.py
模型运行结束后，最优模型和训练log保存在./experiments/clue/路径下。在测试集中的bad case保存在./case/bad_case.txt中。
如要重新运行模型，请先将train.log移出当前路径，以免覆盖。

项目说明参考知乎文章：https://zhuanlan.zhihu.com/p/346828049.本实验只取自其中部分内容。





#### 英文工具：

Nltk：
http://www.nltk.org/index.html
https://github.com/nltk/nltk
https://www.jianshu.com/p/9d232e4a3c28



Spacy：
https://blog.csdn.net/u012436149/article/details/79321112
https://spacy.io/usage/linguistic-features#section-tokenization



Stanfordnlp：
https://github.com/Lynten/stanford-corenlp



**中文工具：** （部分工具命名实体识别没有直接调用的函数，可以根据词性标注的结果自己实现）

Jieba：
https://github.com/fxsjy/jieba

StanfordCoreNLP：
https://github.com/Lynten/stanford-corenlp



SnowNLP：
https://github.com/isnowfy/snownlp
https://www.jianshu.com/p/4692d1b5364d



THULAC：
https://github.com/thunlp/THULAC-Python



NLPIR：
https://github.com/tsroten/pynlpir
https://blog.csdn.net/weixin_34613450/article/details/78695166



HanLP（选做，需要 Microsoft Visual C++ 14.0）
https://github.com/hankcs/pyhanlp